  

## 3.1: Probability Distributions and Probability Mass functions:

  

1. Random Variables are so important that sometimes we forget the actual sample space and start thinking about experiments in terms of possible values of a random variable.

  

1. **Probability distribution**
    
    _For a sample space_, a description of the set of possible outcomes along with a method to determine probabilities. _For a random variable_, a probability distribution is a description of the range along with a method to determine probabilities.
    
      
    
2. Remember what a random variable is from section 2.9:
    
    A function that assigns numerical values to the different outcomes in the sample space.
    

  

1. PMF, Probability Mass function = a function that gives us the probability for the range of values of a discrete random variable X. It is defined as:
    
    $f(x)$ where,
    
    - $f(x_i) ≥ 0$ (probability cannot be negative)
    - $\sum_{i=1}^{n} f(x_i) = 1$ (sum of all probabilities is one)
    - $f(x_i) = P(X = x_i)$ (PMF gives the probabilty of a value of the discrete random variable)
    
      
    

  

1. Review the rule of independence

  

## 3.2 Cumulative Distribution Functions:

  

1. Alternate way to describe a random variable’s probability distribution.
2. This can also be used to find the PMF of a discrete rando variable.

  

1. For X = {1, 2, 3, 4,}
    
    ==$P(x ≤ 3) = P(X = 0) + P(X = 1) + P(X =2 ) + P(X=3)…$==
    
    ==and== ==$P(X=3) = P(X ≤ 3) - P(X ≤ 2)$==
    
      
    

> [!important] In general, for a discrete random variable with possible values ${x_1, x_2, …. x_i}$, the events ${X = x_1}$, ${\{X = x_2\}}$, are mutually exclusive. Therefore,
> 
>   
> ==$P(X ≤ x) = \sum_{x_i ≤ x} P(X = x_i)$==

  

1. **Cumulative Distribution Function:** For a random variable X, the function of X defined as P(X ≤ x) that is used to specify the probability distribution.

  

1. The **CDF** of a discrete random variable X, denoted as F(x), is :  
      
    
    > [!important] ==$F(x) = P(X ≤ x) = \sum_{x_i ≤ x} f(x_i)$====<br><br>==
    > 
    > ==furthermore, F(x) satisfies the following properties:  
    >   
    > ==
    > 
    > - ==0 ≤ F(x) ≤ 1==
    > - ==If x ≤ y, then F(x) ≤ F(y)==
    

  

1. Even though X can only have integers values F(x) is defined for non integer values too such as F(1.5) = P{X=0} P{X = 1}.

  

1. Thus we have the following for a particular example in the book (3.5):
    
    ![[image 63.png|image 63.png]]
    

  

1. ==We can also concur the following:==
    
    ==$P(X = x_i) = F(x_i) - lim_{x→x_i} F(x)$==
    
    ==(difference between== ==$P(X ≤ x_i)$== ==and== ==$P(X ≤ x → x_i)$==
    
      
    
2. Understand the difference between F(x) and f(x), $F(x) = P(X ≤ x)$ and $f(x) = P(X = x)$

  

1. In the picture above, f(x) at any point is the difference between the CDF at that point and the CDF right before.
    
      
    
    X is defined only on 0, 1, 2, 3, 4 because that’s where the X has probability mass (Jumps) probability changes and then stays like that until the next value of X. (F(x)) is still defined on non integer values because P(X ≤ x) is valid for non integral value of x. ==**Think about why just doing P(X ≤ 4) - P(X ≤ 3) gives us P(X = 4) and look at the limit formula and compare for intuition.**==  
      
      
    so PMF at those points will be:  
    
    f(0) , f(1) = F(1)-F(0), f(2) = F(2) - F(1)
    
      
    

  

  
  

## 3.3: Mean and Variance of a Discrete Random Variance:

  

1. The mean of X is the weighted average, the average value or the expected value of X.
    
    ==**Mean**== ==of X,==
    
    ==$E [X] = \mu = \sum_{x_i} x_i \cdot P(X = x_i)$==
    
    ==or,== ==$E [X] = \sum_{x_i} x_i \cdot f(x_i)$==
    
      
    
2. **Variance:**
    
    The **variance** of X measures how spread out the values of X are from the mean (how much they deviate from the expected value). The formula for variance is:
    
      
    
    ==$Var(X) = E[X^2] - (E[X])^2$==
    
    ==$or, \ \ \sigma^2 = E [X] = \sum_{x_i} x^2_i \cdot P(X = x_i)$== ==$- \mu^2$==
    
      
    
3. **Standard deviation** of X is ==$\sigma = \sqrt{\sigma^2}$== ==is the most used measure of variability.==

  

1. The _**Mean**_ of a discrete random variable X is a weighted average of the possible values of X with weights equal to the probabilities. If f(x) is the probability mass function of a loading on a long, thin beam, E(X) is the point at which the beam balances. Consequently, E(X) describes the “center” of the distribution of X in a manner similar to the balance point of a loading. see below:
    
    ![[c03f004.jpg]]
    

  

1. The _**Variance**_ on the other hand, is a measure of scatter in the possible values for X. It is the f(x) multiplier of each possible squared deviation from the mean:
    
    $\sigma^2 = \sum_x (x - \mu)^2$$f(x)$
    

  

1. 2 PDs can be different even if their mean and variances are equal

![[c03f005.jpg]]

  

  

1. Practical interpretation: The mean and the variance summarize a Probability distribution.

  

1. In essence, we calculate variance because it provides a solid mathematical foundation for understanding data spread, while standard deviation serves as the more intuitive, practical measure.

  

1. The expected value (mean) of any function of X say, h(X) is defined as:
    
    > [!important] If X is a discrete random variable with probability mass function f(x) then,==<br><br><br>====$E[h(X)] = \sum_x h(x) f(x)$==
    > 
    > Practical Interpretation: The expected value of a function of a random variable is simply a weighted average of the function evaluated at the values of the random variable.
    

  

1. Generally, h[E(X)] ≠ E[h(X)] however if h(X) = aX + b, then it can be shown that
    
    $E(aX + b) = aE(X) + b$
    
    $and, V(aX + b) = a^2V(X)$
    
      
    

  

## 3.4: Discrete Uniform Distribution:

1. **Discrete uniform distribution:** Where a random variable X, if each of the n values in its range, x1, x2, … xn, has equal probability. Or mathemcatically:
    
    > [!important] $f(x_i) = 1/n$
    

  

> [!important] Suppose X has a discrete uniform distribution. and the range of values is consecutive integers: a, a+1, a+2,…..b<br><br>so,<br>$\mu = \sum_{k=a}^{b} (\frac{1}{b-a+1} \cdot k)$ (why?)<br><br>from a summation identity, this becomes<br><br>
> 
> $\mu = \frac{(b+a)}{2}$  
>   
> ==Derive the variance later !!!  
>   
>   
> ====Thus, we have the following results:  
>   
> Suppose that X is a discrete uniform random variable on the consecutive integers a, a+1…..b. The mean of X is  
> ==
> 
> ==$\mu = E(X) = \frac{b+a}{2}$==
> 
>   
> And the variance is:  
> 
> ==$\sigma^2 = \frac{(b-a+1)^2 - 1}{12}$==

  

  

  

## 3.5: Binomial Distribution:

1. Frequently in real world applications, we have trials in an experiment with only two possible outcomes: success/failure. We usually let X assume the value of number of successes, etc.

  

1. **Bernoulli trials:** Sequences of independent trials with only two outcomes, generally called “success” and “failure,” in which the probability of success remains constant.

  

> [!important]
> 
> ### Binomial Distribution
> 
> - An experiment with n Bernoulli trials.
> - The random variable X that equals the number of trials that result in a success is a binomial random variable.
> - Probability p of any of the trials being a success is constant.
> 
> The probability mass function of X is:
> 
> ==$f(x) = {n\choose x} \cdot p^x \cdot (1-p)^{(n-x)}$==
> 
> $x = {0, 1, ….., n}$  
>   
>   
> Mean and Variance:
> 
> if X is a binomial random variable with parameters p and n,
> 
> ==$\mu = E(X) = np$==
> 
> and
> 
> ==$\sigma^2 = V(X) = np(1 - p)$==

  

  

  

## 3.6 Geometric and Negative Binomial Distributions:

> [!important]
> 
> ### Geometric Distribution
> 
> - **Geometric distribution:** In a series of Bernoulli trials (independent trials with constant probability p of a success), the random variable X that equals the number of trials until the first success is a geometric random variable with parameter 0 < p < 1 and:
>     
>     ==$f(x) = (1-p)^{x-1}\cdot p$==
>     
> 
>   
> 
> - Mean and Variance:
>     
>     - Mean of a geometric random variable is:
>     
>     $\mu = \sum_{k=1}^{\infty} kp(1-p)^{k-1} = p\sum_{k=1}^{\infty}kq^{k-1}$
>     
>     or, ==$\mu = 1/p$== ==(do the derivations)==
>     
>       
>     
>     - ==Variance== ==$= \sigma ^2 = V(X) = (1-p)/p^2$==

  

1. Lack of memory property: Basically, the probability of success after certain trials depends on the number of trials and not the starting point of the trial. For example:
    
    ==if 100 bits are transmitted, the probability that the first error, after bit 100, occurs on bit 106 is the probability that the next six outcomes are OOOOOE. This probability is (0.9)5(0.1) = 0.059, which is identical to the probability that the initial error occurs on bit 6.==
    
      
    

  

> [!important]
> 
> ### Negative Binomial Distribution
> 
>   
> In a series of Bernoulli trials (independent trials with constant probability p of a success), the random variable X that equals the number of trials until r successes occur is a negative binomial random variable with parameters 0 < p < 1 and r = 1, 2, 3,…, and:  
>   
> 
> ==$f(x) = {x-1 \choose r-1}(1-p)^{x-r}p^r$==
> 
>   
> 
> In the special case that r =1, the Negative Binomial distribution is actually just a geometric distribution.
> 
>   
> 
> Also a negative Binomial Distribution X can be represented as the sum of several Geometric distribution variables like $X = X_1 + X_2….$  
>   
>   
> Mean and Variance:
> 
> Mean is just $r/p$ and the variance is $r(1-p)/p^2$

  

1. A binomial random variable is a count of the number of successes in n Bernoulli trials. That is, the number of trials is predetermined, and the number of successes is random. A negative binomial random variable is a count of the number of trials required to obtain r successes. That is, the number of successes is predetermined, and the number of trials is random. In this sense, a negative binomial random variable can be considered the opposite of a binomial random variable.

  

  

## 3.7: Hypergeometric Distribution:

  

1. Definition: Distribution where a set of N objects contains K objects classified as successes, N − K objects classified as failures, and a sample of size n objects is selected randomly (without replacement) from the N objects where K ≤ N and n ≤ N.

  

1. The random variable X that equals the number of successes in the sample is a hypergeometric random variable.

  

1. Probability mass function,
    
    ==$f(x) = \frac{{K \choose x} {N-K \choose n-x}}{{N \choose n}}$==
    

![[image 1 15.png|image 1 15.png]]

Minimum number of successes can be max(0, n + K - N)

  

1. Mean and variance:
    - ==$\mu = E(X) = np$==
    - ==$\sigma^2 = V(X) = np(1-p)(\frac {N-n}{N-1})$==

where p = K/N

  

1. This distribution is very close to the binomial distribution. The only difference is that the set here is finite and there is no replacement (No constant probabilities) (no independence).

  

  

## 3.8: Poisson Distribution:

  

# ==REVIEW THIS SECTION AND FINISH ALL DERIVATIONS!!!==

1. Poisson Process is dividing a long interval of space (length of wire, a roll of textile) T into infinitely small intervals $\Delta t$ average number of flaw in each interval is $\lambda$ and so,

==$f(x) = \frac{e^{-\lambda T} (\lambda T)^x}{x!}$==

  

1. The random variable X equals the number of events in a Poisson process.

  

  

  

  

1. Mean and variance:

- Mean is,
    
    ==$\lambda T \sum_{x = 1}^{\infty} \frac{e^{\lambda T} (\lambda T)^x}{x!}$==
    
    or , $E(X) = \lambda \cdot T$
    

  

- Variance,
    
    ==$V(X) = E(X) = \lambda \cdot T$==