**1.1 The engineering method**

1. The field of statistics deals with the collection, presentation, analysis, and use of data to make decisions, solve problems, and design products and processes.
2. Successive observations of a system or a phenomenon do not produce the same result, this is **variablity**.
    
    Example: The mileage on every full tank is not the same and multiple factors play a role in determining it everytime.
    
      
    
3. **Random variable:**

![[image 61.png|image 61.png]]

[](https://www.notion.soundefined)

μ is constant in a set of successions and epsilon is a random disturbance.

  

1. it is also important to reason from a specific set of measurements to more general cases to answer the previous questions. This reasoning comes from a sample (such as the eight connectors) to a population (such as the connectors that will be in the products that are sold to customers).

  

1. Statistical inference: Reasoning based on measurements from a small specific sample is generalized to a population. This can cause errors which can be handles by handling the sample rightly.

  

6. Randomization: Randomly assign treatments to experimental units or conditions in an experiment. This is done to reduce the opportunity for a treatment to be favored or disfavored (biased) by test conditions.

​

# 1.2 Collecting Engineering Data

1. 3 types of study of data:
    1. Retrospective study (based on logged historical data)
    2. Observational study (factor measurements recorded in real time, more flexible and accurate)
    3. Designed Experiments (controlling inputs and measuring outputs). Most efficient.

  

1. Factorial design (designing experiments) involves listing some factors and deciding on levels (low/high/medium, etc.) for them and then listing all the possible combinations of all the factors, all these combinations are **trials.**

  

1. If there are _k_ factors and n levels then the number of trials would be $n^k$.
2. Fractional factorial experiment is a factorial experiment where only some of the combinations are tested.
3. Often data are collected against time. We might use a time series plot for this.

  

1. Overcontrol/Tampering: Unnecessary adjustments made to processes that increase the deviations from target.
2. Control chart: A graphical display used to monitor a process. It usually consists of a horizontal center line corresponding to the in‐control value of the parameter that is being monitored and lower and upper control limits. The control limits are determined by statistical criteria and are not arbitrary, nor are they related to specification limits. If sample points fall within the control limits, the process is said to be in‐control, or free from assignable causes. Points beyond the control limits indicate an out‐of‐control process; that is, assignable causes are likely present. This signals the need to find and remove the assignable causes.
3. **Enumerative study**: A study in which a sample from a population is used to make inference to the population. See Analytic study.
4. **Analytic study:** A study in which a sample from a population is used to make inference to a future population. Stability needs to be assumed. See Enumerative study.

![[image 1 13.png|image 1 13.png]]

  

# 1.3 Mechanistic and Empirical Models:

1. Models are important in engineering as they help us apply them on situations and processes in problem formulation or solution derivation.
2. **Mechanistic Model:** A model developed from theoretical knowledge or experience in contrast to a model developed from data. See Empirical model.
    
    Example: $I = E/R$
    
      
    
3. **Empirical Model:** A model to relate a response to one or more regressors or factors that is developed from data obtained from the system.
    
    Example: Molecular weight of a polymer, $M_n = b_0 + b_1V + b_2C + b_3T$ + ϵ
    
      
    
    Here V C and T are factors and we say the form of the dependency function is a model developed from a first order taylor series expansion. Epsilon here is to account for several sources of variablity.
    
      
    

# 1.4: Probability and Probability Models.

1. **Probability**: A numerical measure between 0 and 1 assigned to events in a sample space. Higher numbers indicate the event is more likely to occur. See Axioms of probability.

  

1. Probability models combined with a good way to select samples can be useful to quantify the risks of generalization of results to a bigger population.

  

1. “Assume that the same-size sample (such as three wafers) is selected in the same manner from each lot. The proportion of the lots in which the defective wafer are included in the sample or, more specifically, the limit of this proportion as the number of lots in the series tends to infinity, is interpreted as the probability that the defective wafer is detected.”